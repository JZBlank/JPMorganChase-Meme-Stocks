{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327f09e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import vaderSentiment\n",
    "import re\n",
    "import string\n",
    "\n",
    "from collections import defaultdict\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f12b59",
   "metadata": {},
   "source": [
    "Read Data from CSV File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45e87e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\JZ\\Desktop\\Data\\JPMC_data_csv1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    pd.set_option(\"display.max_colwidth\", None) #-1\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb294e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_style(val):\n",
    "    return \"font-weight: normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f290ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalInfo = load().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a44062",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalInfo.style.applymap(df_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill any NaN/invalid values\n",
    "totalInfo = totalInfo.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42886670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of any noisy data (compound score is zero)\n",
    "filter_noise = (totalInfo['compound score '] != '0')\n",
    "totalInfo = totalInfo.loc[filter_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd889663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter special characters\n",
    "def filter_special_chars(comment):\n",
    "    new_sentence = '' #empty string\n",
    "    new_comment = re.sub(r\"https:\\S+\", \"\", comment) #remove url links from comment\n",
    "\n",
    "    for i in range(0, len(new_comment)):\n",
    "        if ord(new_comment[i]) >= 110000: #for characters like ğ´ğ‘€ğ¶ BB  ğ‘ğ‘‚ğ¾ \n",
    "             new_sentence += new_comment[i]\n",
    "        if ord(new_comment[i]) <= 127: #keep all ascii characters\n",
    "            new_sentence += new_comment[i]\n",
    "                \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4dc1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes:              chr(119886 - 119911) = ğ‘ - ğ‘§ \n",
    "#                    chr(119860 - 119885) = ğ´ - ğ‘\n",
    "#                    chr(119912 - 119937) = ğ‘¨ - ğ’\n",
    "\n",
    "#REGULAR chars       chr(97 - 122) = a - z\n",
    "#                    chr(65 - 90)  = A- Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55987e2",
   "metadata": {},
   "source": [
    "Find if sentence has ... in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6155956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sentence(comment): #if text contains â€¦, then it will be removed (â€¦ means truncated)\n",
    "    obj = re.search('â€¦', comment)\n",
    "    if obj != None:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f39f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalInfo['remove'] = totalInfo['text'].map(lambda x: '1' if remove_sentence(x) == 1 else '-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1f5ee",
   "metadata": {},
   "source": [
    "Filter out sentences that are truncated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a196711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_truncated = totalInfo['remove'] == '-1'\n",
    "full_comments_df = totalInfo.loc[filter_truncated]\n",
    "full_comments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a144e",
   "metadata": {},
   "source": [
    "Filter out special characters for full comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4745c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_comments_df['new_text'] = full_comments_df['text'].map(lambda x: filter_special_chars(x)) # remove special char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9173da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments_df = full_comments_df[['Date','text','new_text','favorited', 'retweeted', 'lang', 'quoted_status', 'Stock_Name', 'sentiment', 'sentiment_class', 'compound score ', 'Stock Price', 'remove']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762aa41a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f69a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_comments_df[['text','new_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4fb007",
   "metadata": {},
   "source": [
    "Modifed vaderSentiment Analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = totalInfo['Stock_Name'].to_numpy()\n",
    "stocks\n",
    "\n",
    "all_stocks = set(stocks)\n",
    "all_stocks.remove('Stock_Name')\n",
    "\n",
    "all_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422439cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(comment):\n",
    "    sentence_list = []\n",
    "    stock_sentiment_dict = {}\n",
    "    all_stocks_mentioned = defaultdict(list) # ex: GME:[1, 0.68]\n",
    "                                             # 1 <-- number of times it appeared in comment\n",
    "                                             # 0.68 <-- sum of compound sentimenent scores\n",
    "                                             # Later find average of compound scores ex: 0.68/1 = 0.68 (average)\n",
    "    avg_score = 0\n",
    "    within_comment = nltk.sent_tokenize(comment) #makes a list of all sentences in comment\n",
    "    \n",
    "    for sentence in within_comment:\n",
    "        stocks_seen = set() #within each sentence, keeps track of what stocks are seen\n",
    "        analyzer = SentimentIntensityAnalyzer() #Create analyzer object\n",
    "        vs = analyzer.polarity_scores(sentence) # sentiment of sentence\n",
    "        words = nltk.word_tokenize(sentence) # makes a list of all the words within a sentence\n",
    "        \n",
    "        for word in words: #iterates through each word in sentence\n",
    "            if word in all_stocks: #checks if stock name is a word\n",
    "                if word not in all_stocks_mentioned: #adds word to dictionary if never seen before\n",
    "                    if word not in stocks_seen:\n",
    "                        stock_sentiment_dict[word] = 0\n",
    "                        \n",
    "                        stocks_seen.add(word)\n",
    "                        all_stocks_mentioned[word].append(1)\n",
    "                        all_stocks_mentioned[word].append(vs['compound'])\n",
    "                \n",
    "                else: #if word is already in dictionary (seen before)\n",
    "                    if word not in stocks_seen:\n",
    "                        all_stocks_mentioned[word][0] += 1\n",
    "                        all_stocks_mentioned[word][1] += vs['compound']\n",
    "            \n",
    "    #calculate average compound score for each stock\n",
    "    for name in all_stocks_mentioned.keys():\n",
    "        stock_sentiment_dict[name] = all_stocks_mentioned[name][1] / all_stocks_mentioned[name][0]\n",
    "    \n",
    "    #put average stock sentiment in dictionary\n",
    "    #stock_sentiment_dict[word] = avg_score\n",
    "    print(all_stocks_mentioned)\n",
    "    return stock_sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee976eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Sentiment Analyzer\"\"\"\n",
    "\n",
    "def company_scores(sentence): #returns a dictionary with company names in interest with compound score \n",
    "    sentiment_dict = get_sentiment(sentence)\n",
    "    return sentiment_dict\n",
    "\n",
    "\n",
    "def apply_vadersentiment(df):\n",
    "    df['modified']=df['new_text'].apply(lambda x: company_scores(x))\n",
    "    #df['sentiment_class']=df['sentiment'].apply(lambda x: 'positive' if x['compound']>0.5 else ('negative' if x['compound']<-0.5 else 'neutral'))\n",
    "    #df['compound score']=df['sentiment'].apply(lambda x: x['compound'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c96ce",
   "metadata": {},
   "source": [
    "Obtain all stocks that we are interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25900a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_vadersentiment(full_comments_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
